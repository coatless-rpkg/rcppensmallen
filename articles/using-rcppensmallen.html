<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Solving Linear Regression using Numeric Optimization ‚Ä¢ RcppEnsmallen</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Solving Linear Regression using Numeric Optimization">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">RcppEnsmallen</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.22.1.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/package-usage.html">Using RcppEnsmallen in Your Own R Package</a></li>
    <li><a class="dropdown-item" href="../articles/using-rcppensmallen.html">Solving Linear Regression using Numeric Optimization</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/coatless-rpkg/rcppensmallen/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Solving Linear Regression using Numeric Optimization</h1>
                        <h4 data-toc-skip class="author">James Joseph
Balamuta and Dirk Eddelbuettel</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/coatless-rpkg/rcppensmallen/blob/main/vignettes/using-rcppensmallen.Rmd" class="external-link"><code>vignettes/using-rcppensmallen.Rmd</code></a></small>
      <div class="d-none name"><code>using-rcppensmallen.Rmd</code></div>
    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>In this vignette, we describe how to use RcppEnsmallen in a
      standalone C++ file.</p>
    </div>
    
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<p><code>RcppEnsmallen</code> package provides an embedded copy of the
<a href="https://www.ensmallen.org/docs.html" class="external-link"><code>ensmallen</code></a>
C++ library of optimization functions. Optimizers contained within are
state of the art and possess a high level of code quality. Each
optimizer must be accessed through <em>C++</em> by implementing the
appropriate objective functions and, then, surfaced into <em>R</em>
through <a href="https://cran.r-project.org/package=RcppArmadillo" class="external-link"><code>RcppArmadillo</code></a>.
Alternatively, work has been done by Dirk Schumacher in <a href="https://github.com/dirkschumacher/armacmp" class="external-link"><code>armacmp</code></a>
to automatically create the underlying <em>C++</em> code from
<em>R</em>.</p>
<p><strong>Note:</strong> Optimizers in <code>RcppEnsmallen</code> only
work with <a href="https://arma.sourceforge.net/docs.html" class="external-link"><code>armadillo</code></a>
data structures. Thus, if using <a href="https://eigen.tuxfamily.org/index.php?title=Main_Page" class="external-link"><code>Eigen</code></a>
through <a href="https://cran.r-project.org/package=RcppEigen" class="external-link"><code>RcppEigen</code></a>,
please consider the <a href="https://cran.r-project.org/package=RcppNumerical" class="external-link"><code>RcppNumerical</code></a>
package.</p>
<div class="section level3">
<h3 id="linear-regression">Linear Regression<a class="anchor" aria-label="anchor" href="#linear-regression"></a>
</h3>
<p>Consider the <strong>Residual Sum of Squares</strong>, also known as
<strong>RSS</strong>, defined as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>S</mi><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo>‚àí</mo><mi>ùêó</mi><mi>Œ≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>‚ä§</mi></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo>‚àí</mo><mi>ùêó</mi><mi>Œ≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">RSS\left( \beta \right) = \left( { \mathbf{y} - \mathbf{X} \beta } \right)^{\top} \left( \mathbf{y} - \mathbf{X} \beta \right)</annotation></semantics></math></p>
<p>The objective function we wish to minimize would be defined as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo stretchy="false" form="postfix">‚à•</mo><mi>ùê≤</mi><mo>‚àí</mo><mi>ùêó</mi><mi>Œ≤</mi><msub><mo stretchy="false" form="prefix">‚à•</mo><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">f(\beta) = \rVert \mathbf{y} - \mathbf{X}\beta\lVert_2</annotation></semantics></math></p>
<p>The gradient is defined as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>‚àÇ</mi><mi>R</mi><mi>S</mi><mi>S</mi></mrow><mrow><mi>‚àÇ</mi><mi>Œ≤</mi></mrow></mfrac><mo>=</mo><mo>‚àí</mo><mn>2</mn><msup><mi>ùêó</mi><mi>‚ä§</mi></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo>‚àí</mo><mi>ùêó</mi><mi>Œ≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial RSS}{\partial \beta} = -2 \mathbf{X}^{\top} \left(\mathbf{y} - \mathbf{X} \beta \right)</annotation></semantics></math></p>
<div class="section level4">
<h4 id="two-step-implementation">Two-Step Implementation<a class="anchor" aria-label="anchor" href="#two-step-implementation"></a>
</h4>
<p>When using <code>ensmallen</code> to solve this problem, we must
create a <em>C++</em> class that computes both the objective function
value and its gradient value either together or separately under member
functions named as:</p>
<ul>
<li>
<code>Evaluate()</code>: Value of the objective function under the
parameters.</li>
<li>
<code>Gradient()</code>: Convergence to the correct value under the
given parameters.</li>
<li>
<code>EvaluateWithGradient()</code>: Perform both steps at the same
time. (Optional)</li>
</ul>
<p>In the Linear Regression scenario, we will define each step
separately to emphasize the calculation occurring. Generally, the one
step <code>EvaluateWithGradient()</code> function will be faster than
the two step variant. More details on design can be found on <a href="https://www.ensmallen.org/docs.html#differentiable-functions" class="external-link"><code>ensmallen</code>
documentation page for differentiable functions</a>.</p>
<p>Before writing the class, <code>RcppEnsmallen</code> requires
accessing the library in a standalone C++ file with the follow include
and Rcpp Attribute declarations:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;RcppEnsmallen.h&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">// [[Rcpp::depends(RcppEnsmallen)]]</span></span></code></pre></div>
<p>The overaching Linear regression class should be constructed as
follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;RcppEnsmallen.h&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">// [[Rcpp::depends(RcppEnsmallen)]]</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">// Define a differentiable objective function by implementing both Evaluate()</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">// and Gradient() separately.</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="kw">class</span> LinearRegressionFunction</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="kw">public</span><span class="op">:</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>  <span class="co">// Construct the object with the given the design </span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>  <span class="co">// matrix and responses.</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>  LinearRegressionFunction<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> X<span class="op">,</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>                           <span class="at">const</span> arma<span class="op">::</span>vec<span class="op">&amp;</span> y<span class="op">)</span> <span class="op">:</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>  X<span class="op">(</span>X<span class="op">),</span> y<span class="op">(</span>y<span class="op">)</span> <span class="op">{</span> <span class="op">}</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>  <span class="co">// Return the objective function for model parameters beta.</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>  <span class="dt">double</span> Evaluate<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> beta<span class="op">)</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>      <span class="cf">return</span> <span class="bu">std::</span>pow<span class="op">(</span>arma<span class="op">::</span>norm<span class="op">(</span>y <span class="op">-</span> X <span class="op">*</span> beta<span class="op">),</span> <span class="fl">2.0</span><span class="op">);</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>  <span class="co">// Compute the gradient for model parameters beta</span></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>  <span class="dt">void</span> Gradient<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> beta<span class="op">,</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> g<span class="op">)</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>      g <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> X<span class="op">.</span>t<span class="op">()</span> <span class="op">*</span> <span class="op">(</span>y <span class="op">-</span> X <span class="op">*</span> beta<span class="op">);</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a><span class="kw">private</span><span class="op">:</span></span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>  <span class="co">// The design matrix.</span></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>  <span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> X<span class="op">;</span></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>  <span class="co">// The responses to each data point.</span></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>  <span class="at">const</span> arma<span class="op">::</span>vec<span class="op">&amp;</span> y<span class="op">;</span></span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a><span class="op">};</span></span></code></pre></div>
<p>From there:</p>
<ol style="list-style-type: decimal">
<li>Construct a <em>C++</em> function that exports into <em>R</em>.</li>
<li>Within the function, determine an appropriate optimizer for the
problem.</li>
<li>Combine the optimizer with the linear regression class to compute
the solution to the problem.</li>
</ol>
<p><strong>Note:</strong> Make sure to have the definition of the Linear
Regression class in the same <em>C++</em> file as the exported
<em>C++</em> function into <em>R</em>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>arma<span class="op">::</span>mat lin_reg_lbfgs<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> X<span class="op">,</span> <span class="at">const</span> arma<span class="op">::</span>vec<span class="op">&amp;</span> y<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>  <span class="co">// Construct the first objective function.</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>  LinearRegressionFunction lrf<span class="op">(</span>X<span class="op">,</span> y<span class="op">);</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>  <span class="co">// Create the L_BFGS optimizer with default parameters.</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>  <span class="co">// The ens::L_BFGS type can be replaced with any ensmallen optimizer that can</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>  <span class="co">// handle differentiable functions.</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>  ens<span class="op">::</span>L_BFGS lbfgs<span class="op">;</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>  lbfgs<span class="op">.</span>MaxIterations<span class="op">()</span> <span class="op">=</span> <span class="dv">10</span><span class="op">;</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>  <span class="co">// Create a starting point for our optimization randomly.</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>  <span class="co">// The model has p parameters, so the shape is p x 1.</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>  arma<span class="op">::</span>mat beta<span class="op">(</span>X<span class="op">.</span>n_cols<span class="op">,</span> <span class="dv">1</span><span class="op">,</span> arma<span class="op">::</span>fill<span class="op">::</span>randn<span class="op">);</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>  <span class="co">// Run the optimization</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>  lbfgs<span class="op">.</span>Optimize<span class="op">(</span>lrf<span class="op">,</span> beta<span class="op">);</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>  <span class="cf">return</span> beta<span class="op">;</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="verifying-results">Verifying Results<a class="anchor" aria-label="anchor" href="#verifying-results"></a>
</h4>
<p>Prior to using the new optimizer in mission critical work, compare
the results to methods already implemented in <em>R</em>. The best way
to achieve this is to create an oracle model by specifying the
parameters known to generate data and, then, try to recover them.
Moreover, if a method is already implemented in <em>R</em> feel free to
try to check the result equality within an appropriate tolerance
threshold.</p>
<p>Following with this methodology, data must be generated.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1e6</span></span>
<span><span class="va">beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">1.5</span>, <span class="fl">3</span>, <span class="fl">8.2</span>, <span class="fl">6.6</span><span class="op">)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">beta</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">p</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">/</span> <span class="op">(</span><span class="va">p</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Next, the optimization procedure is used to estimate the parameters
of interest. Under this example, the results of the estimation can be
compared to <code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code>. That said, <code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code> may have
more precise results when compared against the optimizer as it is
implemented with a closed-form solution to linear regression plus the
computational is performed more rigorously.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coefs_lbfgs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lin_reg_lbfgs.html">lin_reg_lbfgs</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span><span class="op">)</span></span>
<span><span class="va">coefs_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lmfit.html" class="external-link">lm.fit</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span></span></code></pre></div>
<table class="table">
<caption>Comparison of Estimated Coefficients</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">LBFGS</th>
<th align="right">LM</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Beta1</td>
<td align="right">-1.997963</td>
<td align="right">-1.997963</td>
</tr>
<tr class="even">
<td align="left">Beta2</td>
<td align="right">1.501261</td>
<td align="right">1.501261</td>
</tr>
<tr class="odd">
<td align="left">Beta3</td>
<td align="right">3.000116</td>
<td align="right">3.000116</td>
</tr>
<tr class="even">
<td align="left">Beta4</td>
<td align="right">8.198827</td>
<td align="right">8.198827</td>
</tr>
<tr class="odd">
<td align="left">Beta5</td>
<td align="right">6.602305</td>
<td align="right">6.602305</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://thecoatlessprofessor.com" class="external-link">James Joseph Balamuta</a>, <a href="https://dirk.eddelbuettel.com/" class="external-link">Dirk Eddelbuettel</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
